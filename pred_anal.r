install.packages("tidyverse")
install.packages("caret")
install.packages("corrplot")
install.packages("randomForest")
install.packages("e1071")
library(tidyverse)
library(caret)
library(corrplot)
library(randomForest)
library(e1071)
heart_data <- read.csv("heart.csv")
str(heart_data)
summary(heart_data)
table(heart_data$output)
sum(is.na(heart_data))
heart_data[is.na(heart_data)] <- lapply(heart_data, function(x) ifelse(is.na(x), median(x,
na.rm = TRUE), x))
cor_matrix <- cor(heart_data[, sapply(heart_data, is.numeric)])
corrplot(cor_matrix, method = "color", tl.cex = 0.7)
set.seed(123) # Ensure reproducibility
train_index <- createDataPartition(heart_data$output, p = 0.8, list = FALSE)
train_data <- heart_data[train_index, ]
test_data <- heart_data[-train_index, ]
log_model <- glm(output ~ ., data = train_data, family = binomial)
summary(log_model)
log_pred <- predict(log_model, test_data, type = "response")
log_pred_class <- ifelse(log_pred > 0.5, 1, 0)
conf_matrix <- table(Predicted = log_pred_class, Actual = test_data$output)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- conf_matrix[2,2] / sum(conf_matrix[,2])
recall <- conf_matrix[2,2] / sum(conf_matrix[2,])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-score:", f1_score, "\n")
rf_model <- randomForest(output ~ ., data = train_data, ntree = 100)
rf_pred <- predict(rf_model, test_data)
rf_conf_matrix <- table(Predicted = rf_pred, Actual = test_data$output)
print(rf_conf_matrix)
rf_accuracy <- sum(diag(rf_conf_matrix)) / sum(rf_conf_matrix)
cat("Logistic Regression Accuracy:", accuracy, "\n")
cat("Random Forest Accuracy:", rf_accuracy, "\n")
scaled_data <- scale(heart_data[, -ncol(heart_data)])
pca_model <- prcomp(scaled_data, center = TRUE, scale. = TRUE)
summary(pca_model)
pca_train <- predict(pca_model, train_data[, -ncol(train_data)])
pca_test <- predict(pca_model, test_data[, -ncol(test_data)])
log_pca_model <- glm(train_data$output ~ ., data = as.data.frame(pca_train), family =
binomial)
log_pca_pred <- predict(log_pca_model, as.data.frame(pca_test), type = "response")
log_pca_class <- ifelse(log_pca_pred > 0.5, 1, 0)
pca_conf_matrix <- table(Predicted = log_pca_class, Actual = test_data$output)
pca_accuracy <- sum(diag(pca_conf_matrix)) / sum(pca_conf_matrix)
cat("PCA-Based Logistic Regression Accuracy:", pca_accuracy, "\n")
svm_model <- svm(output ~ ., data = train_data, kernel = "linear")
svm_pred <- predict(svm_model, test_data)
svm_conf_matrix <- table(Predicted = svm_pred, Actual = test_data$output)
print(svm_conf_matrix)
svm_accuracy <- sum(diag(svm_conf_matrix)) / sum(svm_conf_matrix)
cat("Logistic Regression Accuracy:", accuracy, "\n")
cat("Random Forest Accuracy:", rf_accuracy, "\n")
cat("PCA-Based Logistic Regression Accuracy:", pca_accuracy, "\n")
cat("SVM Accuracy:", svm_accuracy, "\n")
